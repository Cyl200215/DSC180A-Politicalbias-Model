{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertModel, BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the cleaning function to handle non-string values\n",
    "def clean_text(text):\n",
    "    # Check if the text is a string\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove HTML tags and non-alphanumeric characters\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# # Reapply the cleaning function\n",
    "# data['Statement_clean'] = data['statement'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train, test, validation data\n",
    "train_data = pd.read_csv(\"train2.tsv\",sep='\\t', header=None)\n",
    "test_data = pd.read_csv(\"test2.tsv\",sep='\\t', header=None)\n",
    "val_data = pd.read_csv(\"val2.tsv\",sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename all the columns\n",
    "train_data.rename({1: 'id', 2: 'label', 3: 'statement', 4: 'subject', 5: 'speaker', 6: 'job-title',\n",
    "           7: 'state_info', 8: 'party_affiliation', 9: 'barely_true_counts', 10: 'false_counts',\n",
    "           11: 'half_true_counts', 12: 'mostly_true_counts', 13: 'pants_on_fire_counts', 14: 'context',\n",
    "           15: 'justification'\n",
    "          }, axis = 1, inplace = True)\n",
    "test_data.rename({1: 'id', 2: 'label', 3: 'statement', 4: 'subject', 5: 'speaker', 6: 'job-title',\n",
    "           7: 'state_info', 8: 'party_affiliation', 9: 'barely_true_counts', 10: 'false_counts',\n",
    "           11: 'half_true_counts', 12: 'mostly_true_counts', 13: 'pants_on_fire_counts', 14: 'context',\n",
    "           15: 'justification'\n",
    "          }, axis = 1, inplace = True)\n",
    "val_data.rename({1: 'id', 2: 'label', 3: 'statement', 4: 'subject', 5: 'speaker', 6: 'job-title',\n",
    "           7: 'state_info', 8: 'party_affiliation', 9: 'barely_true_counts', 10: 'false_counts',\n",
    "           11: 'half_true_counts', 12: 'mostly_true_counts', 13: 'pants_on_fire_counts', 14: 'context',\n",
    "           15: 'justification'\n",
    "          }, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data, eliminate null values and clean texts\n",
    "train_data['Statement_clean'] = train_data['statement'].apply(clean_text)\n",
    "# train_data['Justification_clean'] = train_data['justification'].apply(clean_text)\n",
    "train_data = train_data[~train_data['label'].isna()]\n",
    "\n",
    "test_data['Statement_clean'] = test_data['statement'].apply(clean_text)\n",
    "# test_data['Justification_clean'] = test_data['justification'].apply(clean_text)\n",
    "test_data = test_data[~test_data['label'].isna()]\n",
    "\n",
    "val_data['Statement_clean'] = val_data['statement'].apply(clean_text)\n",
    "# val_data['Justification_clean'] = val_data['justification'].apply(clean_text)\n",
    "val_data = val_data[~val_data['label'].isna()]\n",
    "\n",
    "# Simple preprocessing\n",
    "train_data['text'] = train_data['Statement_clean']  # Combining Justification + statement\n",
    "train_data = train_data[['text', 'label']]  \n",
    "\n",
    "val_data['text'] = val_data['Statement_clean'] \n",
    "val_data = val_data[['text', 'label']] \n",
    "\n",
    "test_data['text'] = test_data['Statement_clean']\n",
    "test_data = test_data[['text', 'label']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.layer.3.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.output.dense.bias', 'classifier.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'pooler.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'classifier.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.output.LayerNorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Cyl20\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "100%|██████████| 625/625 [40:32<00:00,  3.89s/it] \n",
      "100%|██████████| 625/625 [39:37<00:00,  3.80s/it]\n",
      "100%|██████████| 625/625 [40:55<00:00,  3.93s/it]\n",
      "100%|██████████| 625/625 [15:03<00:00,  1.45s/it]\n",
      "100%|██████████| 161/161 [03:53<00:00,  1.45s/it]\n",
      "c:\\Users\\Cyl20\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Cyl20\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Cyl20\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 159/159 [03:45<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Evaluation:\n",
      " {'0': {'precision': 0.2358490566037736, 'recall': 0.03221649484536082, 'f1-score': 0.05668934240362811, 'support': 776.0}, '1': {'precision': 0.2718978102189781, 'recall': 0.14723320158102768, 'f1-score': 0.191025641025641, 'support': 1012.0}, '2': {'precision': 0.23503569467325644, 'recall': 0.42502482621648463, 'f1-score': 0.3026874115983027, 'support': 1007.0}, '3': {'precision': 0.2138364779874214, 'recall': 0.3497942386831276, 'f1-score': 0.2654176424668228, 'support': 972.0}, '4': {'precision': 0.6666666666666666, 'recall': 0.004901960784313725, 'f1-score': 0.009732360097323601, 'support': 408.0}, '5': {'precision': 0.2017167381974249, 'recall': 0.22787878787878788, 'f1-score': 0.21400113830392717, 'support': 825.0}, 'accuracy': 0.2264, 'macro avg': {'precision': 0.3041670740579202, 'recall': 0.19784158499818372, 'f1-score': 0.17325892264927423, 'support': 5000.0}, 'weighted avg': {'precision': 0.26822515240375044, 'recall': 0.2264, 'f1-score': 0.19612455848017094, 'support': 5000.0}}\n",
      "\n",
      "Validation Set Evaluation:\n",
      " {'0': {'precision': 0.11538461538461539, 'recall': 0.012658227848101266, 'f1-score': 0.022813688212927757, 'support': 237.0}, '1': {'precision': 0.3106060606060606, 'recall': 0.155893536121673, 'f1-score': 0.20759493670886076, 'support': 263.0}, '2': {'precision': 0.24183006535947713, 'recall': 0.4475806451612903, 'f1-score': 0.314002828854314, 'support': 248.0}, '3': {'precision': 0.21256038647342995, 'recall': 0.350597609561753, 'f1-score': 0.2646616541353384, 'support': 251.0}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 116.0}, '5': {'precision': 0.13043478260869565, 'recall': 0.1952662721893491, 'f1-score': 0.15639810426540285, 'support': 169.0}, 'accuracy': 0.21495327102803738, 'macro avg': {'precision': 0.1684693184053798, 'recall': 0.1936660484803611, 'f1-score': 0.16091186869614063, 'support': 1284.0}, 'weighted avg': {'precision': 0.19034699319345685, 'recall': 0.21495327102803738, 'f1-score': 0.17970277945918, 'support': 1284.0}}\n",
      "\n",
      "Test Set Evaluation:\n",
      " {'0': {'precision': 0.07692307692307693, 'recall': 0.009433962264150943, 'f1-score': 0.01680672268907563, 'support': 212.0}, '1': {'precision': 0.26811594202898553, 'recall': 0.14859437751004015, 'f1-score': 0.19121447028423771, 'support': 249.0}, '2': {'precision': 0.2292134831460674, 'recall': 0.3849056603773585, 'f1-score': 0.28732394366197184, 'support': 265.0}, '3': {'precision': 0.18434343434343434, 'recall': 0.3029045643153527, 'f1-score': 0.22919937205651492, 'support': 241.0}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 92.0}, '5': {'precision': 0.1891891891891892, 'recall': 0.23557692307692307, 'f1-score': 0.20985010706638116, 'support': 208.0}, 'accuracy': 0.20757695343330704, 'macro avg': {'precision': 0.15796418760512557, 'recall': 0.18023591459063756, 'f1-score': 0.15573243595969688, 'support': 1267.0}, 'weighted avg': {'precision': 0.17962766687824513, 'recall': 0.20757695343330704, 'f1-score': 0.1785336577085313, 'support': 1267.0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize label encoder\n",
    "label_encoder1 = LabelEncoder()\n",
    "label_encoder2 = LabelEncoder()\n",
    "label_encoder3 = LabelEncoder()\n",
    "\n",
    "# Encode the labels\n",
    "train_data['label'] = label_encoder1.fit_transform(train_data['label'])\n",
    "val_data['label'] = label_encoder2.fit_transform(val_data['label'])\n",
    "test_data['label'] = label_encoder3.fit_transform(test_data['label'])\n",
    "\n",
    "# Split the data (with encoded labels)\n",
    "train_texts = train_data['text'][:5000]\n",
    "val_texts = val_data['text'][:5000]\n",
    "test_texts = test_data['text'][:5000]\n",
    "\n",
    "train_labels = train_data['label'][:5000]\n",
    "val_labels = val_data['label'][:5000]\n",
    "test_labels = test_data['label'][:5000]\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples, padding='max_length', truncation=True, max_length=512)\n",
    "\n",
    "# Apply the tokenizer to the dataset\n",
    "train_encodings = tokenize_function(train_texts.tolist())\n",
    "val_encodings = tokenize_function(val_texts.tolist())\n",
    "test_encodings = tokenize_function(test_texts.tolist())\n",
    "\n",
    "# Dataset class\n",
    "class PoliticalBiasDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Convert to dataset format\n",
    "train_dataset = PoliticalBiasDataset(train_encodings, train_labels.tolist())\n",
    "val_dataset = PoliticalBiasDataset(val_encodings, val_labels.tolist())\n",
    "test_dataset = PoliticalBiasDataset(test_encodings, test_labels.tolist())\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(train_data['label'].unique()))\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=1e-6)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * 3)\n",
    "\n",
    "# Move model to GPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Compute class weights for training loss\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(3):\n",
    "    for batch in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "        loss = loss_fct(outputs.logits.view(-1, len(train_data['label'].unique())), labels.view(-1))\n",
    "        # outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        # loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    references = []\n",
    "    for batch in tqdm(data_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predictions.extend(torch.argmax(logits, dim=-1).tolist())\n",
    "        references.extend(labels.tolist())\n",
    "    return classification_report(references, predictions, output_dict=True)\n",
    "\n",
    "# Evaluate on training, validation, and test sets\n",
    "train_report = evaluate_model(model, train_loader)\n",
    "val_report = evaluate_model(model, val_loader)\n",
    "test_report = evaluate_model(model, test_loader) \n",
    "\n",
    "print(\"Training Set Evaluation:\\n\", train_report)\n",
    "print(\"\\nValidation Set Evaluation:\\n\", val_report)\n",
    "print(\"\\nTest Set Evaluation:\\n\", test_report)\n",
    "\n",
    "# Classification report\n",
    "# print(classification_report(references, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying with Pytorch (Two BERT models in a Siamese Network)\n",
    "\n",
    "**Basic model architecture and ideas from https://github.com/manideep2510/siamese-BERT-fake-news-detection-LIAR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data, eliminate null values and clean texts\n",
    "train_data['Statement_clean'] = train_data['statement'].apply(clean_text)\n",
    "train_data['Justification_clean'] = train_data['justification'].apply(clean_text)\n",
    "train_data = train_data[~train_data['label'].isna()]\n",
    "\n",
    "test_data['Statement_clean'] = test_data['statement'].apply(clean_text)\n",
    "test_data['Justification_clean'] = test_data['justification'].apply(clean_text)\n",
    "test_data = test_data[~test_data['label'].isna()]\n",
    "\n",
    "val_data['Statement_clean'] = val_data['statement'].apply(clean_text)\n",
    "val_data['Justification_clean'] = val_data['justification'].apply(clean_text)\n",
    "val_data = val_data[~val_data['label'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Network\n",
    "class SiameseBERTNetwork(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(SiameseBERTNetwork, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        # Since we are concatenating the outputs, the input features to the linear layer are doubled\n",
    "        self.classifier = nn.Linear(768 * 2, num_labels)\n",
    "\n",
    "    def forward(self, input_ids1, attention_mask1, input_ids2, attention_mask2):\n",
    "        output1 = self.bert(input_ids1, attention_mask=attention_mask1)\n",
    "        output2 = self.bert(input_ids2, attention_mask=attention_mask2)\n",
    "\n",
    "        pooled_output1 = self.dropout(output1.pooler_output)\n",
    "        pooled_output2 = self.dropout(output2.pooler_output)\n",
    "\n",
    "        # Concatenate the outputs\n",
    "        concat_output = torch.cat((pooled_output1, pooled_output2), dim=1)\n",
    "\n",
    "        # Pass through the classifier\n",
    "        logits = self.classifier(concat_output)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dataset class\n",
    "class TextPairDataset(Dataset):\n",
    "    def __init__(self, text_pairs, labels, tokenizer, max_len=128):\n",
    "        self.text_pairs = text_pairs\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        statement, justification = self.text_pairs[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Tokenize the statement\n",
    "        encoded_statement = self.tokenizer(\n",
    "            statement, \n",
    "            padding='max_length', \n",
    "            truncation=True, \n",
    "            max_length=self.max_len, \n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids_statement = encoded_statement['input_ids'].squeeze(0)\n",
    "        attention_mask_statement = encoded_statement['attention_mask'].squeeze(0)\n",
    "\n",
    "        # Tokenize the justification\n",
    "        encoded_justification = self.tokenizer(\n",
    "            justification, \n",
    "            padding='max_length', \n",
    "            truncation=True, \n",
    "            max_length=self.max_len, \n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids_justification = encoded_justification['input_ids'].squeeze(0)\n",
    "        attention_mask_justification = encoded_justification['attention_mask'].squeeze(0)\n",
    "\n",
    "        # Return all the elements as separate items\n",
    "        return input_ids_statement, attention_mask_statement, input_ids_justification, attention_mask_justification, torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "def prepare_data(data):\n",
    "    # Mapping labels to numerical values\n",
    "    label_mapping = {'false': 0, 'half-true': 1, 'mostly-true': 2, 'true': 3, 'barely-true': 4, 'pants-fire': 5}\n",
    "    data['label'] = data['label'].map(label_mapping)\n",
    "    \n",
    "    text_pairs = data[['Statement_clean', 'Justification_clean']].values.tolist()\n",
    "    labels = data['label'].values.tolist()\n",
    "\n",
    "    return text_pairs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train, validation, and test sets\n",
    "train_text_pairs, train_labels = prepare_data(train_data)\n",
    "val_text_pairs, val_labels = prepare_data(val_data)\n",
    "test_text_pairs, test_labels = prepare_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Creating instances of TextPairDataset\n",
    "train_dataset = TextPairDataset(train_text_pairs, train_labels, tokenizer)\n",
    "val_dataset = TextPairDataset(val_text_pairs, val_labels, tokenizer)\n",
    "test_dataset = TextPairDataset(test_text_pairs, test_labels, tokenizer)\n",
    "\n",
    "# Creating DataLoader instances\n",
    "batch_size = 8  \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cyl20\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "100%|██████████| 1280/1280 [27:34<00:00,  1.29s/it]\n",
      "100%|██████████| 161/161 [01:10<00:00,  2.27it/s]\n",
      "c:\\Users\\Cyl20\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Cyl20\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Cyl20\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training Loss: 1.739226478151977\n",
      "Validation Report: {'0': {'precision': 0.45161290322580644, 'recall': 0.053231939163498096, 'f1-score': 0.09523809523809523, 'support': 263.0}, '1': {'precision': 0.20428015564202334, 'recall': 0.42338709677419356, 'f1-score': 0.2755905511811024, 'support': 248.0}, '2': {'precision': 0.2585034013605442, 'recall': 0.6055776892430279, 'f1-score': 0.3623361144219309, 'support': 251.0}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 169.0}, '4': {'precision': 0.2052980132450331, 'recall': 0.1308016877637131, 'f1-score': 0.1597938144329897, 'support': 237.0}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 116.0}, 'accuracy': 0.235202492211838, 'macro avg': {'precision': 0.18661574557890118, 'recall': 0.20216640215740544, 'f1-score': 0.14882642921235303, 'support': 1284.0}, 'weighted avg': {'precision': 0.2203860241652479, 'recall': 0.235202492211838, 'f1-score': 0.17306197389490316, 'support': 1284.0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1280/1280 [34:59<00:00,  1.64s/it]\n",
      "100%|██████████| 161/161 [01:10<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 1.660498518217355\n",
      "Validation Report: {'0': {'precision': 0.28515625, 'recall': 0.27756653992395436, 'f1-score': 0.28131021194605005, 'support': 263.0}, '1': {'precision': 0.24605678233438485, 'recall': 0.31451612903225806, 'f1-score': 0.2761061946902655, 'support': 248.0}, '2': {'precision': 0.26303854875283444, 'recall': 0.46215139442231074, 'f1-score': 0.3352601156069364, 'support': 251.0}, '3': {'precision': 0.26666666666666666, 'recall': 0.023668639053254437, 'f1-score': 0.043478260869565216, 'support': 169.0}, '4': {'precision': 0.23243243243243245, 'recall': 0.18143459915611815, 'f1-score': 0.20379146919431282, 'support': 237.0}, '5': {'precision': 0.4, 'recall': 0.2413793103448276, 'f1-score': 0.3010752688172043, 'support': 116.0}, 'accuracy': 0.26635514018691586, 'macro avg': {'precision': 0.28222511336438644, 'recall': 0.25011943532212055, 'f1-score': 0.24017025352072238, 'support': 1284.0}, 'weighted avg': {'precision': 0.2714906578341449, 'recall': 0.26635514018691586, 'f1-score': 0.247025191986871, 'support': 1284.0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1280/1280 [27:09<00:00,  1.27s/it]\n",
      "100%|██████████| 161/161 [01:10<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Training Loss: 1.364290896523744\n",
      "Validation Report: {'0': {'precision': 0.2777777777777778, 'recall': 0.34220532319391633, 'f1-score': 0.30664395229982966, 'support': 263.0}, '1': {'precision': 0.25671641791044775, 'recall': 0.3467741935483871, 'f1-score': 0.2950257289879931, 'support': 248.0}, '2': {'precision': 0.2764976958525346, 'recall': 0.23904382470119523, 'f1-score': 0.25641025641025644, 'support': 251.0}, '3': {'precision': 0.24444444444444444, 'recall': 0.3254437869822485, 'f1-score': 0.27918781725888325, 'support': 169.0}, '4': {'precision': 0.27631578947368424, 'recall': 0.17721518987341772, 'f1-score': 0.21593830334190234, 'support': 237.0}, '5': {'precision': 0.5483870967741935, 'recall': 0.14655172413793102, 'f1-score': 0.2312925170068027, 'support': 116.0}, 'accuracy': 0.27258566978193144, 'macro avg': {'precision': 0.3133565370388471, 'recall': 0.2628723404061826, 'f1-score': 0.264083095884278, 'support': 1284.0}, 'weighted avg': {'precision': 0.29325000412656815, 'recall': 0.27258566978193144, 'f1-score': 0.26741648410001795, 'support': 1284.0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159/159 [01:09<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Report: {'0': {'precision': 0.26498422712933756, 'recall': 0.3373493975903614, 'f1-score': 0.2968197879858657, 'support': 249.0}, '1': {'precision': 0.2641509433962264, 'recall': 0.3169811320754717, 'f1-score': 0.2881646655231561, 'support': 265.0}, '2': {'precision': 0.29508196721311475, 'recall': 0.2987551867219917, 'f1-score': 0.2969072164948454, 'support': 241.0}, '3': {'precision': 0.27941176470588236, 'recall': 0.27403846153846156, 'f1-score': 0.2766990291262136, 'support': 208.0}, '4': {'precision': 0.2913907284768212, 'recall': 0.20754716981132076, 'f1-score': 0.24242424242424243, 'support': 212.0}, '5': {'precision': 0.3333333333333333, 'recall': 0.11956521739130435, 'f1-score': 0.176, 'support': 92.0}, 'accuracy': 0.27782162588792425, 'macro avg': {'precision': 0.2880588273757859, 'recall': 0.2590394275214853, 'f1-score': 0.26283582359238716, 'support': 1267.0}, 'weighted avg': {'precision': 0.2822849051429693, 'recall': 0.27782162588792425, 'f1-score': 0.2738482558796894, 'support': 1267.0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop \n",
    "def train(model, data_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(data_loader):\n",
    "\n",
    "        # Unpack the data from the dataset\n",
    "        input_ids_statement, attention_mask_statement, input_ids_justification, attention_mask_justification, labels = [b.to(device) for b in batch]\n",
    "        # # Unpack the data from the dataset\n",
    "        # input_ids_statement = batch['input_ids_statement'].to(device)\n",
    "        # attention_mask_statement = batch['attention_mask_statement'].to(device)\n",
    "        # input_ids_justification = batch['input_ids_justification'].to(device)\n",
    "        # attention_mask_justification = batch['attention_mask_justification'].to(device)\n",
    "        # labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids_statement, attention_mask_statement, input_ids_justification, attention_mask_justification)\n",
    "        \n",
    "        loss = loss_function(logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader):\n",
    "            # Unpack the data from the dataset\n",
    "            input_ids_statement, attention_mask_statement, input_ids_justification, attention_mask_justification, labels = [b.to(device) for b in batch]\n",
    "            logits = model(input_ids_statement, attention_mask_statement, input_ids_justification, attention_mask_justification)\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = labels.to('cpu').numpy()\n",
    "\n",
    "            batch_predictions = np.argmax(logits, axis=1)\n",
    "            predictions.extend(batch_predictions)\n",
    "            true_labels.extend(label_ids)\n",
    "\n",
    "    return classification_report(true_labels, predictions, output_dict=True)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "# Model, Optimizer, and Scheduler\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_labels = 6 \n",
    "model = SiameseBERTNetwork(num_labels)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Training and evaluation loop\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, scheduler, device)\n",
    "    val_report = evaluate(model, val_loader, device)\n",
    "    print(f\"Epoch {epoch}, Training Loss: {train_loss}\")\n",
    "    print(f\"Validation Report: {val_report}\")\n",
    "\n",
    "# Evaluate on the test set \n",
    "test_report = evaluate(model, test_loader, device)\n",
    "print(f\"Test Set Evaluation Report: {test_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
